{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHIRbuM5zxco",
        "outputId": "1c3acf07-a9fc-48c9-9f78-f88aa12c1a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RDD --> Resiliant Distributed DataSet!"
      ],
      "metadata": {
        "id": "Ko7HQz3-z-XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create RDD in pyspark\n",
        "\n",
        "####  pyspark.session: It is an entry point to underlying PySpark functionality in order to programmatically create PySpark RDD, DataFrame"
      ],
      "metadata": {
        "id": "gxj6QYcq3vgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "YnsSf8tJ0VTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize([(\"Mumbai\",1),('Delhi',2),('Chennai',3)])"
      ],
      "metadata": {
        "id": "MdxapJT50cEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyt9kco_0m5K",
        "outputId": "6868b6ae-cdb7-4f41-8429-2e3bd9fa3e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsmkTph70r6n",
        "outputId": "d27dbf91-f492-4518-de87-becc10394323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mumbai', 1), ('Delhi', 2), ('Chennai', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRZDqARg0xdS",
        "outputId": "2b5a389c-7218-4953-bd37-7e876c7226c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create a dataframe from RDD"
      ],
      "metadata": {
        "id": "eyG_YT-k31iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datetime import date, datetime"
      ],
      "metadata": {
        "id": "auYOILzz014P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a rdd\n",
        "rdd_1 = spark.sparkContext.parallelize([\n",
        "    (1,1.0,'string1', date(2021,1,1), datetime(2021,1,1,12,0)),\n",
        "    (2,2.0,'string1', date(2021,2,1), datetime(2021,1,2,12,0)),\n",
        "    (3,3.0,'string1', date(2021,3,1), datetime(2021,1,3,12,0))\n",
        "])"
      ],
      "metadata": {
        "id": "CWeQtVdW1Hqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_1 # prints that a rdd is formed but the data is not shown in the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxh7ts0B1uxx",
        "outputId": "aca8b316-d03e-445e-b473-8181b29ecb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[2] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_1.collect() # .collect() shows the output of the rdd and its shown below!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xfjAwqp1vs-",
        "outputId": "456d16ae-c48c-46f3-f472-b4a0e1873a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1,\n",
              "  1.0,\n",
              "  'string1',\n",
              "  datetime.date(2021, 1, 1),\n",
              "  datetime.datetime(2021, 1, 1, 12, 0)),\n",
              " (2,\n",
              "  2.0,\n",
              "  'string1',\n",
              "  datetime.date(2021, 2, 1),\n",
              "  datetime.datetime(2021, 1, 2, 12, 0)),\n",
              " (3,\n",
              "  3.0,\n",
              "  'string1',\n",
              "  datetime.date(2021, 3, 1),\n",
              "  datetime.datetime(2021, 1, 3, 12, 0))]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(rdd_1, schema=['number','float_num','string','date','datetime']) # creating a dataframe from rdd"
      ],
      "metadata": {
        "id": "a4li6NEo1xt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDRLAW0T2Gh_",
        "outputId": "1fdef6e8-99b8-430a-d48d-1b2958fe0a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+-------+----------+-------------------+\n",
            "|number|float_num| string|      date|           datetime|\n",
            "+------+---------+-------+----------+-------------------+\n",
            "|     1|      1.0|string1|2021-01-01|2021-01-01 12:00:00|\n",
            "|     2|      2.0|string1|2021-02-01|2021-01-02 12:00:00|\n",
            "|     3|      3.0|string1|2021-03-01|2021-01-03 12:00:00|\n",
            "+------+---------+-------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUaseLal2HxI",
        "outputId": "baa42ea0-ab30-4d7f-948b-46424baa42d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- number: long (nullable = true)\n",
            " |-- float_num: double (nullable = true)\n",
            " |-- string: string (nullable = true)\n",
            " |-- date: date (nullable = true)\n",
            " |-- datetime: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFa-7woM6APL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}